{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query News Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import dill\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from kss import split_sentences\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from crawler.utils import clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. QueryNewsCrawler class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 line by line coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"코스피\"\n",
    "query = urllib.parse.quote(query)\n",
    "\n",
    "main_url = \"https://search.naver.com/search.naver\"\n",
    "query_url = \"?where=news&sm=tab_pge&query=\"\n",
    "# 네이버 뉴스의 경우 page가 아닌\n",
    "# 뉴스 기사 개수 카운팅으로 보여주고 있음\n",
    "# 1 ~ 4000개까지 10개 단위로 보여줌\n",
    "page_url = \"&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=23&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=\"\n",
    "\n",
    "start = 1\n",
    "start_range = list(range(1, 4000, 10))\n",
    "url = f\"{main_url}{query_url}{query}{page_url}{start}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# req = requests.get(url)\n",
    "# soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "# # ul lists\n",
    "# ul_lists = soup.find(\"ul\", {\"class\": \"list_news\"})\n",
    "# # news links\n",
    "# links = ul_lists.find_all(\"a\", {\"class\": \"news_tit\"})\n",
    "# link_title_dict = {row[\"href\"]: {\"title\": row[\"title\"]} for row in links}\n",
    "\n",
    "\n",
    "# # update news texts\n",
    "# news_texts = ul_lists.find_all(\"a\", {\"class\": \"api_txt_lines dsc_txt_wrap\"})\n",
    "# for row in news_texts:\n",
    "#     link_title_dict[row[\"href\"]][\"text\"] = row.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request and soup\n",
    "req = requests.get(url)\n",
    "soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "# ul lists and li lists\n",
    "ul_lists = soup.find(\"ul\", {\"class\": \"list_news\"})\n",
    "li_lists = ul_lists.findChildren(\"li\", {\"class\": \"bx\"})\n",
    "\n",
    "news_data = []\n",
    "for li in li_lists:\n",
    "\n",
    "    # news link & title\n",
    "    link = li.find(\"a\", {\"class\": \"news_tit\"})\n",
    "    href, title = link[\"href\"], link[\"title\"]\n",
    "\n",
    "    # news text\n",
    "    text = li.find(\"a\", {\"class\": \"api_txt_lines dsc_txt_wrap\"}).text\n",
    "\n",
    "    # thumb nail if exist\n",
    "    thumb = \"\"\n",
    "    thumb_link = li.find(\"img\", {\"class\": \"thumb api_get\"})\n",
    "    if thumb_link:\n",
    "        thumb = thumb_link[\"src\"]\n",
    "\n",
    "    # update link_title_dict\n",
    "    news_data.append({\"href\": href, \"title\": title, \"text\": text, \"thumb\": thumb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryNewsCrawler:\n",
    "    def __init__(self):\n",
    "        # 네이버 뉴스의 경우 page가 아닌\n",
    "        # 뉴스 기사 개수 카운팅으로 보여주고 있음\n",
    "        # 1 ~ 4000개까지 10개 단위로 보여줌\n",
    "        self.main_url = \"https://search.naver.com/search.naver\"\n",
    "        self.query_url = \"?where=news&sm=tab_pge&query=\"\n",
    "        self.page_url = \"&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=23&mynews=0&office_type=0&\"\n",
    "        self.page_url += (\n",
    "            \"office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=\"\n",
    "        )\n",
    "\n",
    "    def crawl_news_by_query(self, query: str, count: int = 200) -> List[Dict]:\n",
    "        self.query = query\n",
    "        parsed_query = urllib.parse.quote(query)\n",
    "\n",
    "        if count:\n",
    "            start_range = list(range(1, count, 10))\n",
    "        else:\n",
    "            start_range = list(range(1, 4000, 10))\n",
    "\n",
    "        news_data = []\n",
    "        for s_idx in tqdm(start_range):\n",
    "            url = f\"{self.main_url}{self.query_url}{parsed_query}{self.page_url}{s_idx}\"\n",
    "\n",
    "            # request and soup\n",
    "            req = requests.get(url)\n",
    "            soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "            # ul lists and li lists\n",
    "            ul_lists = soup.find(\"ul\", {\"class\": \"list_news\"})\n",
    "            li_lists = ul_lists.findChildren(\"li\", {\"class\": \"bx\"})\n",
    "            for li in li_lists:\n",
    "                # news link & title\n",
    "                link = li.find(\"a\", {\"class\": \"news_tit\"})\n",
    "                href, title = link[\"href\"], link[\"title\"]\n",
    "                # news text\n",
    "                text = li.find(\"a\", {\"class\": \"api_txt_lines dsc_txt_wrap\"}).text\n",
    "                # thumb nail if exist\n",
    "                thumb = \"\"\n",
    "                thumb_link = li.find(\"img\", {\"class\": \"thumb api_get\"})\n",
    "                if thumb_link:\n",
    "                    thumb = thumb_link[\"src\"]\n",
    "\n",
    "                # update link_title_dict\n",
    "                news_data.append(\n",
    "                    {\"href\": href, \"title\": title, \"text\": text, \"thumb\": thumb}\n",
    "                )\n",
    "            time.sleep(random.uniform(0.6, 0.9))\n",
    "\n",
    "        return news_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = QueryNewsCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "query = \"코스피\"\n",
    "count = 20\n",
    "news_data = crawler.crawl_news_by_query(query=query, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'href': 'http://www.newsis.com/view/?id=NISX20220314_0001792931&cID=15001&pID=15000',\n",
       "  'title': '美금리인상 임박…코스피 2500선 하락 우려도',\n",
       "  'text': '5%p 인상 \\'빅스텝\\' 가능성도 열어둬 주중 선반영시 코스피 2500대 하락 우려 증권가 \"0.25%p 올리고 정책조정... 코스피가 이 같은 연준의 빅스텝(0.5%포인트 인상)을 선반영할 경우 주중 2600선 아래로 떨어질 수 있다는...',\n",
       "  'thumb': 'https://search.pstatic.net/common/?src=https%3A%2F%2Fimgnews.pstatic.net%2Fimage%2Forigin%2F003%2F2022%2F03%2F15%2F11062029.jpg&type=ff264_180&expire=2&refresh=true'},\n",
       " {'href': 'http://yna.kr/AKR20220315122700002?did=1195m',\n",
       "  'title': '긴축 우려 등에 코스피 사흘째 하락…2,620대로 밀려',\n",
       "  'text': '코스닥지수, 혼조 흐름 속 하락 마감 코스피가 사흘째 하락하며 2,620대까지 밀렸다. 15일 코스피는 전 거래일보다 24.12포인트(0.91%) 내린 2,621.53에 마감했다. 지수는 전장보다 15.34포인트(0.58%) 낮은 2,630....',\n",
       "  'thumb': 'https://search.pstatic.net/common/?src=https%3A%2F%2Fimgnews.pstatic.net%2Fimage%2Forigin%2F001%2F2022%2F03%2F15%2F13052478.jpg&type=ff264_180&expire=2&refresh=true'}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca37adc465479a74c6a141ab03dbdf7641081253eef51a46dbf42999bc11eb1a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pt-py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
